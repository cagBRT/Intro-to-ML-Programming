{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroToMachineLearningProgramming_Spanish.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Intro-to-ML-Programming/blob/master/IntroToMachineLearningProgramming_Spanish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7xlEP-4w4m1"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Intro-to-ML-Programming.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5d-rhNzNIN9"
      },
      "source": [
        "from IPython.display import Image\n",
        "def page(num):\n",
        "    #print(str(num))\n",
        "    return Image(\"Intro to Machine Learning Programming (\"+ str(num) + \").png\")\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ3hbZm4N9un"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"Intro to Machine Learning Programming.png\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google CoLab es similar a Jupyter Notebooks. Ambos corren iPython, que es la versión interactiva de Python."
      ],
      "metadata": {
        "id": "A5Kng6CNnHmQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdSFpIDtTx2j"
      },
      "source": [
        "Cuando una celda se corre, el código se compila y ejecuta. <br>\n",
        "El usuario puede correr una celda, hacer cambios y correr la celda de nuevo. <br>\n",
        "<br>\n",
        "Para guardar los cambios, descargue el archivo: **Archivo>Descargar .ipynb**\n",
        "o **Archivo>Guardar una copia en Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kktdx3WOOL9_"
      },
      "source": [
        "page(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "051PFZq_Ky8c"
      },
      "source": [
        "page(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQVSaVMEz9Qf"
      },
      "source": [
        "page(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AObBB94FQOQ0"
      },
      "source": [
        "page(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_FNHMBBuaYO"
      },
      "source": [
        "# Use seaborn for pairplot\n",
        "!pip install seaborn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuQfdDw9t0Ic"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyL3OKa9zkaL"
      },
      "source": [
        "page(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj343NMQ9Uut"
      },
      "source": [
        "page(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYU6c8pATpJ3"
      },
      "source": [
        "#Regresión: predecir la eficiencia del combustible\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jno8ASzx_YIC"
      },
      "source": [
        "page(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fQWaVkylI32"
      },
      "source": [
        "page(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isPTWHCZnGZR"
      },
      "source": [
        "**Nota**: estamos tratando de generar el menor error general para las predicciones de nuestro modelo .....esto implica que....**esperamos un poco de error en nuestro modelo de machine learning!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ibHs9SN9oGN"
      },
      "source": [
        " page(9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El-SEe9mUaeS"
      },
      "source": [
        "En un problema de regresión, buscamos predecir la salida de un valor continuo, como un precio o una probabilidad. Contrario a un problema de clasificación, donde buscamos seleccionar una clase de una lista de clases (por ejemplo, si una imagen tiene una manzana o una naranja, reconociendo qué fruta está en la imagen).\n",
        "\n",
        "Este notebook usa el clásico conjunto de datos [Auto MPG Dataset](https://archive.ics.uci.edu/ml/datasets/auto+mpg) y construye un modelo para predecir la eficiencia de la gasolina en vehículos de finales de 1970 y principios de 1980. Para lograrlo proveemos al modelo con una descripción de muchos automóbiles de la época. Esta descripción incluye características como: cilindros, desplazamiento, poder y peso. \n",
        "\n",
        "Este ejemplo utiliza tf.keras API, ver [esta guía](https://www.tensorflow.org/guide/keras) para más detalles. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2LZui9eWLoL"
      },
      "source": [
        "##Conjunto de datos :  Auto MPG dataset\n",
        "El conjunto de datos que utilizamos es de dominio público y está disponible en  [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvHVdXuxWhyW"
      },
      "source": [
        "### Obtenga los datos\n",
        "Primero descargue el conjunto de datos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjcAq5X4Ww58"
      },
      "source": [
        "Impórtela utilizando pandas.\n",
        "\n",
        "Pandas puede importar 14 diferentes tipos de archivos. Este conjunto de datos se guarda en un archivo CSV.<br>\n",
        "[14 tipos de archivos que pueden importarse con Pandas](https://www.cbtnuggets.com/blog/technology/programming/14-file-types-you-can-import-into-pandas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb9cOS5WVwYd"
      },
      "source": [
        "page(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn5wKbyAuhob"
      },
      "source": [
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAhKcICF-ZOu"
      },
      "source": [
        "page(11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYqHRT07KWru"
      },
      "source": [
        "page(12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyx-ftElullo"
      },
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zS52QFETvxW"
      },
      "source": [
        "page(13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFzQYCgwKJ5i"
      },
      "source": [
        "Imprima los primeros renglones del conjunto de datos, esto lo ayudará a entender mejor sus datos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzTqNJtcGR57"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YaS1HbKlG2T"
      },
      "source": [
        "### Prepare los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zK7GXRTTY-u"
      },
      "source": [
        "page(14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ87-bNLTkaW"
      },
      "source": [
        "###Limpie los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LamhjvDhuoLY"
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tqqn6VrGnKU"
      },
      "source": [
        "Para este tutorial, elimine los renglones que contienen NA. En algunos casos, en vez de esto, puede ser necesario cambiar los valores faltantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCmsdAA2urM3"
      },
      "source": [
        "dataset = dataset.dropna()\n",
        "dataset.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9m3H_3vtr3e"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRF193U-uGGm"
      },
      "source": [
        "También puede revisar las veces que aparece cada valor en un una columna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0euzNtNt0if"
      },
      "source": [
        "dataset['Cylinders'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80RdCe_cWzsl"
      },
      "source": [
        "###Convierta los datos categóricos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gv3JUA7mUCq"
      },
      "source": [
        "La columna `\"Origin\"` es categórica no numérica. Por ello conviértala a one-hot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAS7cwPyL6rm"
      },
      "source": [
        "page(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkRqMVRSuuQw"
      },
      "source": [
        "origin = dataset.pop('Origin')\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULBG91iUrRkn"
      },
      "source": [
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgd7898Suy-J"
      },
      "source": [
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKNV0_cYm_GQ"
      },
      "source": [
        "###Divida los datos en entrenamiento y prueba. \n",
        "Ahora separe el conjunto de datos en un conjunto de entrenamiento y otro de prueba.\n",
        "\n",
        "Utilizaremos los datos de prueba en la evaluación final de nuestro modelo. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiWfVQz5MBGO"
      },
      "source": [
        "page(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p9qU-wsu12c"
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv11n2IJnF2r"
      },
      "source": [
        "### Inspeccione los datos\n",
        "\n",
        "Dé una revisión rápida a la distribución conjunta de algunas columnas de los datos de entrenamiento. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnlJF1uDu14u"
      },
      "source": [
        "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc-BJdtUHlte"
      },
      "source": [
        "Dé una revisión rápida a la distribución conjunta de algunas columnas de los datos de prueba. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAgLfVw9HfyC"
      },
      "source": [
        "sns.pairplot(test_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_oKhu1_nLML"
      },
      "source": [
        "También observe las estadísticas generales. <br> Las estadísticas de los datos de prueba y entrenamiento deben ser similares. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6l0b9eEu7qJ"
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpogLVNYHrxq"
      },
      "source": [
        "test_stats = test_dataset.describe()\n",
        "test_stats.pop(\"MPG\")\n",
        "test_stats = test_stats.transpose()\n",
        "test_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRTzQ1vznRDh"
      },
      "source": [
        "### Separe las caracterísiticas de las etiquetas. \n",
        "\n",
        "Separe el valor deseado o \"etiqueta\" (label) de las características. Usted entrenará al modelo para predecir esta etiqueta.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7hOAALs6OcT"
      },
      "source": [
        "page(17)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNPm34vAMcRI"
      },
      "source": [
        "page(18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J1K03vqu_TL"
      },
      "source": [
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNQ0oNx3nWto"
      },
      "source": [
        "### Normalice los datos\n",
        "\n",
        "Observe nuevamente el bloque `train_stats` que se encuentra más arriba y note lo diferentes que son los rangos de cada característica. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QkoJwzEMf3f"
      },
      "source": [
        "page(19)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yq9kQlkna5V"
      },
      "source": [
        "Es buena práctica normalizar las características que utilizan diferentes escalas y rangos. Aunque el modelo *puede* converger sin una normalización, hace el entrenamiento más dificil y hace que el modelo resultante sea dependiente de la elección de unidades utilizadas en la entrada. \n",
        "\n",
        "Nota: aunque nosotros generamos intencionalmente estas estadísticas solo para el conjunto de datos de entrenamiento, estas estadísticas también serán utilizadas para normalizar la bases de datos de prueba. Es necesario hacer esto para proyectar el conjunto de datos de prueba en la misma distribución con el que el modelo ha sido entrenado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehaQyUlYu_Vb"
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nDvuRZRUPBcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9NWmHuvnkBO"
      },
      "source": [
        "Estos datos normalizados son los que usaremos para entrenar el modelo. \n",
        "\n",
        "Precaución: Las estadísticas utilizadas aquí para normalizar las entradas (promedio y desviación estandar) deben ser aplicadas a cualquier otro grupo de datos con el que se alimente al modelo, adicional a la codificación one-hot que realizamos anteriornmente. Esto incluye a los datos de prueba asi como datos en tiempo real cuando ya se utilice en producción.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr05L9C-nn3X"
      },
      "source": [
        "## El modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH3UtKudMmmN"
      },
      "source": [
        "page(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8hRDl0q7TeV"
      },
      "source": [
        "page(21)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLXCuq5bI96E"
      },
      "source": [
        "###Defina el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuifNbWBvE86"
      },
      "source": [
        "inputs = len(train_dataset.keys())\n",
        "print(\"number of inputs to the model = \" + str(inputs))\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    #input_shape=(9,),\n",
        "    layers.Dense(64, activation=tf.nn.relu,input_shape=([len(train_dataset.keys())]),),\n",
        "    layers.Dense(64, activation=tf.nn.relu),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mean_squared_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "  return model\n",
        "  print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuLqDLYVnse_"
      },
      "source": [
        "### Construya el modelo\n",
        "\n",
        "Construyamos nuestro modelo. Aquí utilizaremos un modelo secuencial (`Sequential`) con dos capas escondidas (hidden layers) densamente conectadas y una capa de salida que entregue un solo valor continuo. Los pasos de construcción del modelo son envueltos en una función, `build_model`, ya que más adelante crearemos un segundo modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AWO9qoivE-9"
      },
      "source": [
        "model = build_model()\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euDM8-x3ny1z"
      },
      "source": [
        "Inspeccione el modelo. \n",
        "\n",
        "Utilice el método `.summary` para imprimir una descripción simple del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgG_jimRvJs-"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKvwq4yfM2yk"
      },
      "source": [
        "page(22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70CAspBBoL3K"
      },
      "source": [
        "### Entrene el modelo\n",
        "\n",
        "Entrene el modelo por 1000 ciclos (epochs) y registre el entrenamiento y la precisión de validación en la historia (`history`) del objeto. \n",
        "\n",
        "Vocabulario de Machine Learning (ML): https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0K_0meUBxL4"
      },
      "source": [
        "page(23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR99uJl4B1oK"
      },
      "source": [
        "page(24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xKk3yrJNHsn"
      },
      "source": [
        "page(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upfCzQ4pNON_"
      },
      "source": [
        "page(26)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UyGV_pgNQdt"
      },
      "source": [
        "page(27)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAFaC8BLNSnT"
      },
      "source": [
        "page(28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLhiTWMfNVKD"
      },
      "source": [
        "page(29)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaTgY-eZNXgC"
      },
      "source": [
        "page(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJRA3Al0NcSc"
      },
      "source": [
        "page(31)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l5NeV3YCUq7"
      },
      "source": [
        "page(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqlc49utCRQa"
      },
      "source": [
        "page(33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSIFYnldvX25"
      },
      "source": [
        "# Display training progress by printing a single dot for each completed epoch\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbjeiXNqoQlL"
      },
      "source": [
        "Visualice el progreso de entrenamiento del modelo utilizando las estadísticas almacenadas en la historia (`history`) del objeto. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V09cmOaQxOgk"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmOQ9d4gOVVP"
      },
      "source": [
        "page(35)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px44SralOavI"
      },
      "source": [
        "page(36)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSRLxfs75k89"
      },
      "source": [
        "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRbcj5jQvkcW"
      },
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXQQ76TFobtX"
      },
      "source": [
        "La gráfica muestra las pequeñas mejoras e incluso degradaciones en el error de la validación después de 100 ciclos (epochs). Actualicemos el `model.fit`llamado para detener el entrenamiento automáticamente cuando el puntaje de validación no mejora. Utilizaremos el *EarlyStopping callback* que prueba una condición entrenada para cada ciclo (epoch). Si transcurre un grupo de ciclos (epochs) sin mostrar mejorías, entonces se detiene el entrenamiento automáticamente. \n",
        "\n",
        "Usted puede aprender más sobre esta función (callback) [aquí.](https://keras.io/callbacks/#earlystopping)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYggU5TAOjbk"
      },
      "source": [
        "page(37)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy-bUOxa7PFk"
      },
      "source": [
        "Usted también puede ahorrar tiempo al realizar mucho menos ciclos (epochs). Ahora que usted sabe donde comienza el sobreajuste (overfitting) ... deténgalo justo antes de ese punto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK0vc8KtvnXz"
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9NBW3MZohez"
      },
      "source": [
        "Esta gráfica muestra que en el conjunto de validación, el error promedio está usualmente entre +/- 2 MPG. Esto será bueno? Dejaremos esa decisión para usted. \n",
        "\n",
        "Veamos que tán bien generaliza el modelo al utilizar los datos de **prueba** que no utilizamos al entrenar el modelo. Esto nos dice qué tan bien puede predecir el modelo cuando lo utilicemos en el mundo real. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZEgJYfCvna3"
      },
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=0)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Iohx0ppoz2Y"
      },
      "source": [
        "### Pruebe el modelo\n",
        "\n",
        "Finalmente, prediga los valores MPG utilizando los datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW_O_dHgI3iH"
      },
      "source": [
        "page(38)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADROBEKYyvoi"
      },
      "source": [
        "page(39)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgxftPkGvyhI"
      },
      "source": [
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXo53NWHo4kt"
      },
      "source": [
        "Parece que nuestro modelo predice rasonablemente bien. Revisemos la distribucuón del error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmPX0Sykv2nh"
      },
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\n",
        "_ = plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIJSKTvMo8sq"
      },
      "source": [
        "No parece gausiano, pero podemos esperar eso porque el número de muestras es muy pequeño. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ANnz2iFyhwA"
      },
      "source": [
        "page(40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVdPywWQIeNu"
      },
      "source": [
        "page(41)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06isr_DLIYyt"
      },
      "source": [
        "page(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgoK_0O82aPf"
      },
      "source": [
        "#Normalized data\n",
        "trial=([1, 1, 1, 1, 1, 1, 1.0, 0.0, 0.0],)\n",
        "trial_predictions = model.predict(trial).flatten()\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8awUqsh53VRr"
      },
      "source": [
        "print(trial_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5swi1UupBx6"
      },
      "source": [
        "## Conclusión\n",
        "\n",
        "Este notebook introduce algunas técnicas para manejar un problema de regresión. \n",
        "\n",
        "* El error cuadrático medio (MSE) es una función de riesgo (loss function) comúnu utilizada en problemas de regresión (diferentes funciones de riesgo son utilizadas para la clasificación de problemas).\n",
        "* Similarmente, las métricas de regresión difieren de las de clasificación. Una métrica de regresión común es el error medio absoluto (MAE). \n",
        "* Cuando las características numéricas de la entrada de datos tienen valores con rangos diferentes, cada característica debe ser escalada independientemente al mismo rango. \n",
        "* Si no hay muchos datos de entrenamiento, una técnica es optar por una red más pequeña con capas (layers) escondidas para evitar el sobreajuste (overfitting).\n",
        "* Una suspención temprana es una técnica útil para revenir el sobreajuste (overfitting)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKS-FM-LhXpI"
      },
      "source": [
        "# Porfavor proporcione una retroalimentación:\n",
        "\n",
        "[Retroalimentación del curso](https://docs.google.com/forms/d/e/1FAIpQLScMf6j9h9Yxm5zdUhoSPsXEP_c5ruO2ZDmNYTDlW-9XKQ3Ogg/viewform?usp=pp_url)"
      ]
    }
  ]
}